{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series \n",
    "how you mark and refer to time series data depends on the application, and you may have one of the following  \n",
    "* Timestamps, specific instants in time\n",
    "* fixed periods, such as the month jan 2007 or the full year 2010\n",
    "* intervals of time, indicated by a start and end timestamp. Periods can be thought of as special cases of intervals\n",
    "* Experiment or elapsed time; each timestamp is a measure of time relative to a particular start time(e.g. the diameter of a cookie baking each seocond since being placed in the oven)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2020, 8, 4, 12, 44, 6, 529635)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2020, 8, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now.year, now.month, now.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(926, 56700)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta = datetime(2011, 1, 7) - datetime(2008, 6, 24, 8, 15)\n",
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 1, 31, 0, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "start = datetime(2011, 1, 7)\n",
    "start + 2 * timedelta(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Between String and Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1998-12-28 00:00:00'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stamp = datetime(1998, 12, 28)\n",
    "str(stamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1998-12-28'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stamp.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime format specification \n",
    "%Y -- four  \n",
    "%y -- Two-digit year  \n",
    "%m -- Two-digit month  \n",
    "%d -- Two-digit day  \n",
    "%H -- Hour (24 hour clock)  \n",
    "%I -- House (12 hour clock)  \n",
    "%M -- Two-digit minute   \n",
    "%S -- Second [00,61] 61 account for leap second  \n",
    "%w -- Weekday as integer [0(sunday), 6]  \n",
    "%U -- Week number of the year [0-53]; sunday is considered the first day of the week, and days before the first sunday of the year are \"week 0\"   \n",
    "%W -- Week number of the year [00, 53] Monday is considered the first day of the week, and days before the first monday of the year are week \"0\"\n",
    "%z -- UTC time zone offset as +HHMM or -HHMM; empty if time zone naive   \n",
    "%F -- Shortcut for %Y-%m-%d  \n",
    "%D -- Shortcut for %m/%d/%y   \n",
    "<br/>\n",
    "you can use the same methods to convert strings to dates using datetime.strptime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2011, 1, 3, 0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value = '2011-01-03'\n",
    "datetime.strptime(value, '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02    0.342957\n",
       "2011-01-05   -1.095502\n",
       "2011-01-07    2.092905\n",
       "2011-01-08   -0.152931\n",
       "2011-01-10   -1.758786\n",
       "2011-01-12   -1.015951\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dates = [datetime(2011, 1, 2), datetime(2011, 1, 5), datetime(2011, 1, 7), datetime(2011, 1, 8), datetime(2011, 1, 10), datetime(2011, 1, 12)]\n",
    "ts = pd.Series(np.random.randn(6), index=dates)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2011-01-02', '2011-01-05', '2011-01-07', '2011-01-08',\n",
       "               '2011-01-10', '2011-01-12'],\n",
       "              dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02    0.685914\n",
       "2011-01-05         NaN\n",
       "2011-01-07    4.185811\n",
       "2011-01-08         NaN\n",
       "2011-01-10   -3.517572\n",
       "2011-01-12         NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts + ts[::2] # selects every other point and doubles them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2011-01-02 00:00:00')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stamp = ts.index[0]\n",
    "stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3429570414720186"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[stamp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3429570414720186"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['2011/01/02'] # can pass a date as a string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002-09-22   -0.494385\n",
       "2002-09-23   -0.226518\n",
       "2002-09-24    0.856928\n",
       "2002-09-25    0.209116\n",
       "2002-09-26    0.177636\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for larger series sets \n",
    "longer_ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n",
    "longer_ts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001-12-27    0.963591\n",
       "2001-12-28   -0.296360\n",
       "2001-12-29    1.119830\n",
       "2001-12-30   -0.676404\n",
       "2001-12-31   -1.928090\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_ts['2001'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002-05-27    0.372464\n",
       "2002-05-28   -0.456472\n",
       "2002-05-29    0.900367\n",
       "2002-05-30   -0.654095\n",
       "2002-05-31   -0.382102\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer_ts['2002-05'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02    0.342957\n",
       "2011-01-05   -1.095502\n",
       "2011-01-07    2.092905\n",
       "2011-01-08   -0.152931\n",
       "2011-01-10   -1.758786\n",
       "2011-01-12   -1.015951\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts[datetime(2009, 5, 5):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-07    2.092905\n",
       "2011-01-08   -0.152931\n",
       "2011-01-10   -1.758786\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts['1/6/2011':'1/11/2011']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02    0.342957\n",
       "2011-01-05   -1.095502\n",
       "2011-01-07    2.092905\n",
       "2011-01-08   -0.152931\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.truncate(after='1/9/2011')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series with Duplicate Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002-01-01   -0.401372\n",
       "2002-01-02    0.578632\n",
       "2002-01-03    0.322778\n",
       "2002-01-02   -0.660494\n",
       "2002-01-02   -0.977648\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.DatetimeIndex(['1/1/2002', '1/2/2002', '1/3/2002', '1/2/2002', '1/2/2002' ])\n",
    "dup_ts = pd.Series(np.random.randn(5), index=dates)\n",
    "dup_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2002-01-01', '2002-01-02', '2002-01-03'], dtype='datetime64[ns]', freq=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_ts.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002-01-01   -0.401372\n",
       "2002-01-02   -0.353170\n",
       "2002-01-03    0.322778\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# suppose you wanted to group non-unique dates\n",
    "non_unique = dup_ts.groupby(level=0)\n",
    "non_unique.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002-01-01    1\n",
       "2002-01-02    3\n",
       "2002-01-03    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_unique.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Ranges Frequencies and shifting  \n",
    "often you time series may have non-uniform date ranges. For most purposes this is fine but should you whish to have equidistant dates you may whish to use the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02    0.342957\n",
       "2011-01-05   -1.095502\n",
       "2011-01-07    2.092905\n",
       "2011-01-08   -0.152931\n",
       "2011-01-10   -1.758786\n",
       "2011-01-12   -1.015951\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2011-01-02    0.342957\n",
       "2011-01-03         NaN\n",
       "2011-01-04         NaN\n",
       "2011-01-05   -1.095502\n",
       "2011-01-06         NaN\n",
       "2011-01-07    2.092905\n",
       "2011-01-08   -0.152931\n",
       "2011-01-09         NaN\n",
       "2011-01-10   -1.758786\n",
       "2011-01-11         NaN\n",
       "2011-01-12   -1.015951\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampler = ts.resample('D') #D for daily\n",
    "resampler.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2009-04-01', '2009-04-02', '2009-04-03', '2009-04-04',\n",
       "               '2009-04-05', '2009-04-06', '2009-04-07', '2009-04-08',\n",
       "               '2009-04-09', '2009-04-10', '2009-04-11', '2009-04-12',\n",
       "               '2009-04-13', '2009-04-14', '2009-04-15', '2009-04-16',\n",
       "               '2009-04-17', '2009-04-18', '2009-04-19', '2009-04-20',\n",
       "               '2009-04-21', '2009-04-22', '2009-04-23', '2009-04-24',\n",
       "               '2009-04-25', '2009-04-26', '2009-04-27', '2009-04-28',\n",
       "               '2009-04-29', '2009-04-30', '2009-05-01'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pd.date_range('2009-04-01', '2009-05-01')\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2 = pd.date_range(start='1998-12-28', periods=365) #can also used 'end' as arg\n",
    "# should you have wanted a index that just referenced the last business day of the month\n",
    "index2 = pd.date_range(start='1998-12-28', end='2020-12-28', freq='BM') # 'BM' for business month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base time series frequencies \n",
    "D -- Day   \n",
    "B -- BusinessDay   \n",
    "H -- Hour  \n",
    "T/min -- Minute   \n",
    "S -- Second  \n",
    "L/ms -- milli  \n",
    "U -- Micro  \n",
    "M -- MonthEnd  \n",
    "BM -- BusinessMonthEnd  \n",
    "MS -- MonthBegin  \n",
    "BMS -- BusinessMonthBegin   \n",
    "W-MON, W-TUE -- Week    \n",
    "WOM-1MON/WOM-2MON -- Generates dates in first/second/third/fourth week of the month.    \n",
    "Q-JAN/Q-FEB -- Quater end anchord on last calendar name of each month  \n",
    "BQ-JAN/BQ-FEB -- Business Quater End. Quaterly dates anchored on last weekday of each month  \n",
    "QS-JAN/QS-FEB -- Quaterly dates anchored on first calendar day of each month.    \n",
    "BQS-JAN/BQS-FEB -- Quarterly dates anchored onf irst weekday of each mont, for year ending in indicated month.   \n",
    "A-JAN/A-FEB -- Annual dates anchored on last calendar day of given month   \n",
    "BA-JAN/BA-FEB -- Annual dates anchored on last weekday of given month   \n",
    "AS-JAN/AS-FEB -- Annual dates anchored on first daty of given month  \n",
    "BAS-JAN/BAS-FEB -- Annual dates anchored on frist weekday of given month.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2001-11-23 12:56:31', '2001-11-24 12:56:31',\n",
       "               '2001-11-25 12:56:31', '2001-11-26 12:56:31',\n",
       "               '2001-11-27 12:56:31'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range('2001-11-23 12:56:31', periods=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2001-11-23', '2001-11-24', '2001-11-25', '2001-11-26',\n",
       "               '2001-11-27'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range('2001-11-23 12:56:31', periods=5, normalize=True) #should you want to normalise them to midnight "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting Data\n",
    "moving information around by shifting date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1998-12-05   -0.353879\n",
       "1998-12-06   -0.463790\n",
       "1998-12-07   -1.287616\n",
       "1998-12-08   -0.930545\n",
       "1998-12-09    1.623138\n",
       "1998-12-10   -1.473908\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = pd.date_range('1998-12-05', periods = 6)\n",
    "ts = pd.Series(np.random.randn(6), index=dates)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1998-12-05         NaN\n",
       "1998-12-06         NaN\n",
       "1998-12-07         NaN\n",
       "1998-12-08   -0.353879\n",
       "1998-12-09   -0.463790\n",
       "1998-12-10   -1.287616\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1998-12-05   -1.287616\n",
       "1998-12-06   -0.930545\n",
       "1998-12-07    1.623138\n",
       "1998-12-08   -1.473908\n",
       "1998-12-09         NaN\n",
       "1998-12-10         NaN\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1998-12-05 00:01:30   -0.353879\n",
       "1998-12-06 00:01:30   -0.463790\n",
       "1998-12-07 00:01:30   -1.287616\n",
       "1998-12-08 00:01:30   -0.930545\n",
       "1998-12-09 00:01:30    1.623138\n",
       "1998-12-10 00:01:30   -1.473908\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.shift(1, freq='90S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Zone Handling\n",
    "working with time zones is considered to be a pain. As a result many time series used choose to with with UTC, the succsesor to GMT. IT is the current international standard. Time zones are expressed as offsets from UTC. In python, time zone information comes from pytz lirary. You can install it with pip or conda. pandas wraps pytz's functionalty so you can ignore its API outside of the time zone names. Time zone names can be found interactively and in the docs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['US/Eastern', 'US/Hawaii', 'US/Mountain', 'US/Pacific', 'UTC']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pytz \n",
    "pytz.common_timezones[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DstTzInfo 'America/New_York' LMT-1 day, 19:04:00 STD>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get a time zone object from pytz, use pytz.timezone\n",
    "tz = pytz.timezone('America/New_York')\n",
    "tz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Zone Localization and Conversion\n",
    "By default, Time series in pandas are time zone naive. For example, consider the following time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-09 09:20:00', '2012-03-10 09:20:00',\n",
       "               '2012-03-11 09:20:00', '2012-03-12 09:20:00',\n",
       "               '2012-03-13 09:20:00', '2012-03-14 09:20:00',\n",
       "               '2012-03-15 09:20:00'],\n",
       "              dtype='datetime64[ns]', freq='D')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('3/9/2012 9:20', periods=7, freq='D')\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-09 09:20:00   -0.919565\n",
       "2012-03-10 09:20:00    0.355124\n",
       "2012-03-11 09:20:00    1.363503\n",
       "2012-03-12 09:20:00    0.551122\n",
       "2012-03-13 09:20:00   -1.313585\n",
       "2012-03-14 09:20:00    0.313324\n",
       "2012-03-15 09:20:00    0.228200\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ts.index.tz) # Shows the series does not have an associated timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-09 09:30:00+00:00', '2012-03-10 09:30:00+00:00',\n",
       "               '2012-03-11 09:30:00+00:00', '2012-03-12 09:30:00+00:00',\n",
       "               '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00',\n",
       "               '2012-03-15 09:30:00+00:00', '2012-03-16 09:30:00+00:00',\n",
       "               '2012-03-17 09:30:00+00:00', '2012-03-18 09:30:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', freq='D')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.date_range('3/9/2012 9:30', periods=10, freq='D', tz='UTC') #can pass a series a timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-09 09:20:00+00:00   -0.919565\n",
       "2012-03-10 09:20:00+00:00    0.355124\n",
       "2012-03-11 09:20:00+00:00    1.363503\n",
       "2012-03-12 09:20:00+00:00    0.551122\n",
       "2012-03-13 09:20:00+00:00   -1.313585\n",
       "2012-03-14 09:20:00+00:00    0.313324\n",
       "2012-03-15 09:20:00+00:00    0.228200\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_utc = ts.tz_localize('UTC') #localises time series to UTC \n",
    "ts_utc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-09 09:20:00+00:00', '2012-03-10 09:20:00+00:00',\n",
       "               '2012-03-11 09:20:00+00:00', '2012-03-12 09:20:00+00:00',\n",
       "               '2012-03-13 09:20:00+00:00', '2012-03-14 09:20:00+00:00',\n",
       "               '2012-03-15 09:20:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', freq='D')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_utc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-09 04:20:00-05:00   -0.919565\n",
       "2012-03-10 04:20:00-05:00    0.355124\n",
       "2012-03-11 05:20:00-04:00    1.363503\n",
       "2012-03-12 05:20:00-04:00    0.551122\n",
       "2012-03-13 05:20:00-04:00   -1.313585\n",
       "2012-03-14 05:20:00-04:00    0.313324\n",
       "2012-03-15 05:20:00-04:00    0.228200\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_utc.tz_convert('America/New_York') # converts it to another time zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-09 14:20:00+00:00   -0.919565\n",
       "2012-03-10 14:20:00+00:00    0.355124\n",
       "2012-03-11 13:20:00+00:00    1.363503\n",
       "2012-03-12 13:20:00+00:00    0.551122\n",
       "2012-03-13 13:20:00+00:00   -1.313585\n",
       "2012-03-14 13:20:00+00:00    0.313324\n",
       "2012-03-15 13:20:00+00:00    0.228200\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_eastern = ts.tz_localize('America/New_York') #localise to America/New_York\n",
    "ts_eastern.tz_convert('UTC') #Converts to UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-09 15:20:00+01:00   -0.919565\n",
       "2012-03-10 15:20:00+01:00    0.355124\n",
       "2012-03-11 14:20:00+01:00    1.363503\n",
       "2012-03-12 14:20:00+01:00    0.551122\n",
       "2012-03-13 14:20:00+01:00   -1.313585\n",
       "2012-03-14 14:20:00+01:00    0.313324\n",
       "2012-03-15 14:20:00+01:00    0.228200\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_eastern.tz_convert('Europe/Berlin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations Between Different Time Zones\n",
    "If two Series with different time zones are combined, the result will be UTC. Since the timestamps are stored under the hood in UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-07 09:30:00   -1.008152\n",
       "2012-03-08 09:30:00   -0.145881\n",
       "2012-03-09 09:30:00    0.857205\n",
       "2012-03-12 09:30:00    1.367619\n",
       "2012-03-13 09:30:00    0.613715\n",
       "2012-03-14 09:30:00   -0.425579\n",
       "2012-03-15 09:30:00    0.361737\n",
       "2012-03-16 09:30:00    1.274083\n",
       "2012-03-19 09:30:00    0.506632\n",
       "2012-03-20 09:30:00    0.572335\n",
       "Freq: B, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('3/7/2012 9:30', periods=10, freq='B')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2012-03-07 09:30:00+00:00', '2012-03-08 09:30:00+00:00',\n",
       "               '2012-03-09 09:30:00+00:00', '2012-03-12 09:30:00+00:00',\n",
       "               '2012-03-13 09:30:00+00:00', '2012-03-14 09:30:00+00:00',\n",
       "               '2012-03-15 09:30:00+00:00'],\n",
       "              dtype='datetime64[ns, UTC]', freq='B')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts1 = ts[:7].tz_localize('Europe/London')\n",
    "ts2 = ts1[2:].tz_convert('Europe/Moscow')\n",
    "result = ts1 + ts2\n",
    "result.index # Resultant time zone is UTC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Periods and Period Arithmetic \n",
    "Periods represent timespanes, like days, months, quaters or years. The period is represented by the Period class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2007', 'A-DEC')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.Period(2007, freq='A-Dec')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2012', 'A-DEC')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addidng and subtracting shift the periods date \n",
    "p + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2000-01', '2000-02', '2000-03', '2000-04', '2000-05', '2000-06'], dtype='period[M]', freq='M')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regular ranges or periods can be constructed with period_range\n",
    "rng = pd.period_range('2000-01-01', '2000-06-30', freq='M')\n",
    "rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01   -1.637263\n",
       "2000-02   -0.302098\n",
       "2000-03   -0.671930\n",
       "2000-04    1.017570\n",
       "2000-05   -0.111502\n",
       "2000-06    1.055387\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.random.randn(len(rng)), index=rng) #can use as an axis index in data strucutre. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## period Freqency Conversion\n",
    "for example shoudl you have a period index of a year and whish to convert it into months \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2007', 'A-DEC')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = pd.Period('2007', freq='A-DEC')\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2007-01', 'M')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.asfreq('M', how='start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Period('2007-12', 'M')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.asfreq('M', how='end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " PeriodIndex objects or time series can be similarly converted with the same sematincs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006   -1.675085\n",
       "2007    0.848519\n",
       "2008    0.393645\n",
       "2009   -0.761129\n",
       "2010    0.669436\n",
       "2011   -0.603207\n",
       "2012   -0.737702\n",
       "Freq: A-DEC, dtype: float64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.period_range('2006','2012', freq='A-DEC')\n",
    "p = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2006-12-29   -1.675085\n",
       "2007-12-31    0.848519\n",
       "2008-12-31    0.393645\n",
       "2009-12-31   -0.761129\n",
       "2010-12-31    0.669436\n",
       "2011-12-30   -0.603207\n",
       "2012-12-31   -0.737702\n",
       "Freq: B, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.asfreq('B', how='end') # last business day of each year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Timestamps to Peridos (and Back)\n",
    "Series and DataFrame objects indexed by timestamps can be converted to periods with the to_period method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31    1.189275\n",
       "2000-02-29    0.112156\n",
       "2000-03-31    0.228564\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('2000-01-01', periods=3, freq='M')\n",
    "ts = pd.Series(np.random.randn(3), index=rng)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01   -0.781802\n",
       "2000-02    0.853108\n",
       "2000-03    1.117287\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts = ts.to_period()\n",
    "pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since periods refer to non-overlapping timespans, a timestamp can only belong to a single period. There however is no issue with having multiple numbers of the same period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-29   -1.335982\n",
       "2000-01-30   -0.838258\n",
       "2000-01-31    0.125719\n",
       "2000-02-01    0.294786\n",
       "2000-02-02    0.263647\n",
       "2000-02-03   -0.700288\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('1/29/2000', periods=6, freq='D')\n",
    "ts2 = pd.Series(np.random.randn(6), index=rng)\n",
    "ts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01   -1.335982\n",
       "2000-01   -0.838258\n",
       "2000-01    0.125719\n",
       "2000-02    0.294786\n",
       "2000-02    0.263647\n",
       "2000-02   -0.700288\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts2 = ts2.to_period('M')\n",
    "pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To convert back to timestamp use to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31 23:59:59.999999999   -1.335982\n",
       "2000-01-31 23:59:59.999999999   -0.838258\n",
       "2000-01-31 23:59:59.999999999    0.125719\n",
       "2000-02-29 23:59:59.999999999    0.294786\n",
       "2000-02-29 23:59:59.999999999    0.263647\n",
       "2000-02-29 23:59:59.999999999   -0.700288\n",
       "dtype: float64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts3 = pts2.to_timestamp(how='end')\n",
    "ts3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling and Frequency conversion\n",
    "resampling referes to the process of converting a time series from one frequncy to antoher. downsampling, converts to lower frequency where upsampling refers to higher frequency. the resample method is the main workhorse for all frequency conversion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    0.873980\n",
       "2000-01-02    1.106158\n",
       "2000-01-03    0.813009\n",
       "2000-01-04    0.623379\n",
       "2000-01-05   -0.722063\n",
       "2000-01-06    0.444274\n",
       "2000-01-07    1.054500\n",
       "2000-01-08   -1.209713\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = pd.date_range('2000-01-01', periods=100, freq='D')\n",
    "ts = pd.Series(np.random.randn(len(rng)), index=rng)\n",
    "ts.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-31    0.081158\n",
       "2000-02-29   -0.239076\n",
       "2000-03-31   -0.011235\n",
       "2000-04-30   -0.059235\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('M').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01    0.081158\n",
       "2000-02   -0.239076\n",
       "2000-03   -0.011235\n",
       "2000-04   -0.059235\n",
       "Freq: M, dtype: float64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts.resample('M', kind='period').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample method arguments  \n",
    "freq -- String or DateOffset indicating desired resampled frequency\n",
    "axis -- Axis to resample on; default=0  \n",
    "fill_method -- How to interpolate when upsampling as in 'ffill', or 'bfill';    \n",
    "closed -- In downsampling, which ened of each interval is closed 'right' or 'left'.    \n",
    "label -- In downsampling, how to lavel the aggregated result with the 'right' or 'left' bin edge    \n",
    "limit -- When foward or backward filling, the maximum number of periods to fill.   \n",
    "kind -- Aggregate to periods or timestamps 'period' or 'timestamp'   \n",
    "convention -- When resampling periods, the convention('start' or'end' for converting the low-frequncy period to high frequency'; defaults to 'start'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
