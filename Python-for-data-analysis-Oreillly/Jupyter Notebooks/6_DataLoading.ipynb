{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595491475798",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading, Storage, and File Formats\n",
    "functions for reading tabular data into a dataframe \n",
    ".  \n",
    ".  \n",
    "read_csv -- Load data from a file, URL, or file-like object; use comma as default delimiter  \n",
    "read_fwf -- Read data in fixed-width column format   \n",
    "read_clipboard -- Version of read_csv that reads data from the clipboard; useful for converiting tables from web pages  \n",
    "read_excel -- read tabular data from an XLS or XLSX file   \n",
    "read_hdf -- Read HDF5 files written by pandas  \n",
    "read_html -- Read all tables found in the given HTML documnet   \n",
    "read_json -- Read data from a JSON string representation   \n",
    "read_msgpack -- Read pandas data encoded using the MessagePack binary format    \n",
    "read_pickle -- Read an arbitrary object stored in Python pickle format   \n",
    "read_sas -- Read a SAS dataset stored in one of the SAS system's custom storage Formats  \n",
    "read_sql -- Read the results of a SQL query as a pandas DataFrame   \n",
    "read_stata -- Read a dataset from stata file format   \n",
    "read_feather -- Read the Feather binary file format  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   a   b   c   d message\n0  1   2   3   4   hello\n1  5   6   7   8   world\n2  9  10  11  12     foo",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n      <th>d</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>hello</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>world</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9</td>\n      <td>10</td>\n      <td>11</td>\n      <td>12</td>\n      <td>foo</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('exampledata/ex1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A file will not always have a header row. You can load a dataframe without a header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   0   1   2   3        4\n0  a   b   c   d  message\n1  1   2   3   4    hello\n2  5   6   7   8    world\n3  9  10  11  12      foo",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>b</td>\n      <td>c</td>\n      <td>d</td>\n      <td>message</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>hello</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>world</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>10</td>\n      <td>11</td>\n      <td>12</td>\n      <td>foo</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "df = pd.read_csv('exampledata/ex1.csv', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to specify the header yourself you can use the following code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   a   b   c   d  message\n0  a   b   c   d  message\n1  1   2   3   4    hello\n2  5   6   7   8    world\n3  9  10  11  12      foo",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n      <th>d</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a</td>\n      <td>b</td>\n      <td>c</td>\n      <td>d</td>\n      <td>message</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>hello</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n      <td>world</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>10</td>\n      <td>11</td>\n      <td>12</td>\n      <td>foo</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df2 = pd.read_csv('exampledata/ex1.csv', names=['a', 'b', 'c', 'd', 'message'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted a column to be the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         a   b   c   d\nmessage               \nhello    1   2   3   4\nworld    5   6   7   8\nfoo      9  10  11  12",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n      <th>d</th>\n    </tr>\n    <tr>\n      <th>message</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>hello</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>world</th>\n      <td>5</td>\n      <td>6</td>\n      <td>7</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>foo</th>\n      <td>9</td>\n      <td>10</td>\n      <td>11</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df = pd.read_csv('exampledata/ex1.csv', index_col='message')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "message\nhello     2\nworld     6\nfoo      10\nName: b, dtype: int64"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should your data file represent missing cells in a certain way e.g. Na, missing, Nan you can specify this to pandas and it   \n",
    "will replace it with its own missing format. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('exampledata/ex1.csv', na_values=['Null']) #pandas will replace the missing value with its own sentinel NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Read CSV functions \n",
    "path -- String indicating filesystem location, URL, or file-like object   \n",
    "sep or delimiter -- Character sequence or regular expression to use to split fields in each row  \n",
    "header -- Row number to use as column names; defaults to 0 (frist row), but should be None if there is no header row \n",
    "index_col -- Column number or names to use as the row index in the result; can be a single name/nmber or a list of them for a hierachical index   \n",
    "names -- List of column names for result, combine with header=None\n",
    "skiprows -- Number of rows at beginning of file to ignore or list of row numbers to skip. \n",
    "na_values -- Sequence of values to replace with na_valuescomment -- Characters to split comments of the end of lines. \n",
    "parse_dates -- Attempt to parse data to datetime; False by default. If True, will attempt to parse all columns, Otherwise can specify a list of column numbers or name to parse. If  \n",
    "               element of list is tuple or list, will combine multiple columns together and parse to date \n",
    "dayfirst -- When parsing potentially ambiguous dates, treat as international format, False by default  \n",
    "nrows -- Number of rows to read from beginning of file\n",
    "iterator -- Return a TextParser object for reading file piecemeal  \n",
    "chinksize -- for iteration, size of file chunks   \n",
    "skip_footer -- number of lines to ignore at end of file   \n",
    ".  \n",
    ".  \n",
    ".  \n",
    ".  \n",
    "# Reading Text Files in Pieces\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Sell   \"List\"   \"Living\"   \"Rooms\"   \"Beds\"   \"Baths\"   \"Age\"   \"Acres\"  \\\n0   142      160         28        10        5         3      60      0.28   \n1   175      180         18         8        4         1      12      0.43   \n2   129      132         13         6        3         1      41      0.33   \n3   138      140         17         7        3         1      22      0.46   \n4   232      240         25         8        4         3       5      2.05   \n\n    \"Taxes\"  \n0      3167  \n1      4033  \n2      1471  \n3      3204  \n4      3613  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sell</th>\n      <th>\"List\"</th>\n      <th>\"Living\"</th>\n      <th>\"Rooms\"</th>\n      <th>\"Beds\"</th>\n      <th>\"Baths\"</th>\n      <th>\"Age\"</th>\n      <th>\"Acres\"</th>\n      <th>\"Taxes\"</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>142</td>\n      <td>160</td>\n      <td>28</td>\n      <td>10</td>\n      <td>5</td>\n      <td>3</td>\n      <td>60</td>\n      <td>0.28</td>\n      <td>3167</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>175</td>\n      <td>180</td>\n      <td>18</td>\n      <td>8</td>\n      <td>4</td>\n      <td>1</td>\n      <td>12</td>\n      <td>0.43</td>\n      <td>4033</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>129</td>\n      <td>132</td>\n      <td>13</td>\n      <td>6</td>\n      <td>3</td>\n      <td>1</td>\n      <td>41</td>\n      <td>0.33</td>\n      <td>1471</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>138</td>\n      <td>140</td>\n      <td>17</td>\n      <td>7</td>\n      <td>3</td>\n      <td>1</td>\n      <td>22</td>\n      <td>0.46</td>\n      <td>3204</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>232</td>\n      <td>240</td>\n      <td>25</td>\n      <td>8</td>\n      <td>4</td>\n      <td>3</td>\n      <td>5</td>\n      <td>2.05</td>\n      <td>3613</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "pd.read_csv('exampledata/homes.csv', nrows=5) #reads just 5 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<pandas.io.parsers.TextFileReader at 0x2707a6f2700>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# to read in a number of chunks \n",
    "chunker = pd.read_csv('exampledata/homes.csv', chunksize=10) # Specifies the number of rows per chunk\n",
    "chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "152    2.0\n129    2.0\n157    2.0\n175    2.0\n180    2.0\n135    2.0\n110    2.0\n148    2.0\n123    1.0\n127    1.0\n128    1.0\n111    1.0\n133    1.0\n150    1.0\n136    1.0\n106    1.0\n138    1.0\n142    1.0\n143    1.0\n145    1.0\n89     1.0\n146    1.0\n567    1.0\n151    1.0\n190    1.0\n271    1.0\n265    1.0\n247    1.0\n234    1.0\n232    1.0\n212    1.0\n207    1.0\n185    1.0\n293    1.0\n184    1.0\n183    1.0\n170    1.0\n167    1.0\n166    1.0\n165    1.0\n153    1.0\n87     1.0\ndtype: float64"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "tot = pd.Series([])\n",
    "for piece in chunker:\n",
    "    #print('Piece value counts: \\n', piece['Sell'].value_counts())\n",
    "    tot = tot.add(piece['Sell'].value_counts(), fill_value=0)#.value counts returns a count of unique values. fill_value specifies what value to give missing data.\n",
    "\n",
    "tot = tot.sort_values(ascending=False)\n",
    "tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing data to Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "|Sell|\" \"\"List\"\"\"|\" \"\"Living\"\"\"|\" \"\"Rooms\"\"\"|\" \"\"Beds\"\"\"|\" \"\"Baths\"\"\"|\" \"\"Age\"\"\"|\" \"\"Acres\"\"\"|\" \"\"Taxes\"\"\"\n0|142|160|28|10|5|3|60|0.28|3167\n1|175|180|18|8|4|1|12|0.43|4033\n2|129|132|13|6|3|1|41|0.33|1471\n3|138|140|17|7|3|1|22|0.46|3204\n4|232|240|25|8|4|3|5|2.05|3613\n5|135|140|18|7|4|3|9|0.57|3028\n6|150|160|20|8|4|3|18|4.0|3131\n7|207|225|22|8|4|2|16|2.22|5158\n8|271|285|30|10|5|2|30|0.53|5702\n9|89|90|10|5|3|1|43|0.3|2054\n10|153|157|22|8|3|3|18|0.38|4127\n11|87|90|16|7|3|1|50|0.65|1445\n12|234|238|25|8|4|2|2|1.61|2087\n13|106|116|20|8|4|1|13|0.22|2818\n14|175|180|22|8|4|2|15|2.06|3917\n15|165|170|17|8|4|2|33|0.46|2220\n16|166|170|23|9|4|2|37|0.27|3498\n17|136|140|19|7|3|1|22|0.63|3607\n18|148|160|17|7|3|2|13|0.36|3648\n19|151|153|19|8|4|2|24|0.34|3561\n20|180|190|24|9|4|2|10|1.55|4681\n21|293|305|26|8|4|3|6|0.46|7088\n22|167|170|20|9|4|2|46|0.46|3482\n23|190|193|22|9|5|2|37|0.48|3920\n24|184|190|21|9|5|2|27|1.3|4162\n25|157|165|20|8|4|2|7|0.3|3785\n26|110|115|16|8|4|1|26|0.29|3103\n27|135|145|18|7|4|1|35|0.43|3363\n28|567|625|64|11|4|4|4|0.85|12192\n29|180|185|20|8|4|2|11|1.0|3831\n30|183|188|17|7|3|2|16|3.0|3564\n31|185|193|20|9|3|2|56|6.49|3765\n32|152|155|17|8|4|1|33|0.7|3361\n33|148|153|13|6|3|2|22|0.39|3950\n34|152|159|15|7|3|1|25|0.59|3055\n35|146|150|16|7|3|1|31|0.36|2950\n36|170|190|24|10|3|2|33|0.57|3346\n37|127|130|20|8|4|1|65|0.4|3334\n38|265|270|36|10|6|3|33|1.2|5853\n39|157|163|18|8|4|2|12|1.13|3982\n40|128|135|17|9|4|1|25|0.52|3374\n41|110|120|15|8|4|2|11|0.59|3119\n42|123|130|18|8|4|2|43|0.39|3268\n43|212|230|39|12|5|3|202|4.29|3648\n44|145|145|18|8|4|2|44|0.22|2783\n45|129|135|10|6|3|1|15|1.0|2438\n46|143|145|21|7|4|2|10|1.2|3529\n47|247|252|29|9|4|2|4|1.25|4626\n48|111|120|15|8|3|1|97|1.11|3205\n49|133|145|26|7|3|1|42|0.36|3059\n"
    }
   ],
   "source": [
    "data = pd.read_csv('exampledata/homes.csv')\n",
    "data.to_csv('exampledata/ouput.csv')\n",
    "\n",
    "#To use other delimeter formats\n",
    "import sys \n",
    "data.to_csv(sys.stdout,  sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ",Sell,\" \"\"List\"\"\",\" \"\"Living\"\"\",\" \"\"Rooms\"\"\",\" \"\"Beds\"\"\",\" \"\"Baths\"\"\",\" \"\"Age\"\"\",\" \"\"Acres\"\"\",\" \"\"Taxes\"\"\"\n0,142,160,28,10,5,3,60,0.28,3167\n1,175,180,18,8,4,1,12,0.43,4033\n2,129,132,13,6,3,1,41,0.33,1471\n3,138,140,17,7,3,1,22,0.46,3204\n4,232,240,25,8,4,3,5,2.05,3613\n5,135,140,18,7,4,3,9,0.57,3028\n6,150,160,20,8,4,3,18,4.0,3131\n7,207,225,22,8,4,2,16,2.22,5158\n8,271,285,30,10,5,2,30,0.53,5702\n9,89,90,10,5,3,1,43,0.3,2054\n10,153,157,22,8,3,3,18,0.38,4127\n11,87,90,16,7,3,1,50,0.65,1445\n12,234,238,25,8,4,2,2,1.61,2087\n13,106,116,20,8,4,1,13,0.22,2818\n14,175,180,22,8,4,2,15,2.06,3917\n15,165,170,17,8,4,2,33,0.46,2220\n16,166,170,23,9,4,2,37,0.27,3498\n17,136,140,19,7,3,1,22,0.63,3607\n18,148,160,17,7,3,2,13,0.36,3648\n19,151,153,19,8,4,2,24,0.34,3561\n20,180,190,24,9,4,2,10,1.55,4681\n21,293,305,26,8,4,3,6,0.46,7088\n22,167,170,20,9,4,2,46,0.46,3482\n23,190,193,22,9,5,2,37,0.48,3920\n24,184,190,21,9,5,2,27,1.3,4162\n25,157,165,20,8,4,2,7,0.3,3785\n26,110,115,16,8,4,1,26,0.29,3103\n27,135,145,18,7,4,1,35,0.43,3363\n28,567,625,64,11,4,4,4,0.85,12192\n29,180,185,20,8,4,2,11,1.0,3831\n30,183,188,17,7,3,2,16,3.0,3564\n31,185,193,20,9,3,2,56,6.49,3765\n32,152,155,17,8,4,1,33,0.7,3361\n33,148,153,13,6,3,2,22,0.39,3950\n34,152,159,15,7,3,1,25,0.59,3055\n35,146,150,16,7,3,1,31,0.36,2950\n36,170,190,24,10,3,2,33,0.57,3346\n37,127,130,20,8,4,1,65,0.4,3334\n38,265,270,36,10,6,3,33,1.2,5853\n39,157,163,18,8,4,2,12,1.13,3982\n40,128,135,17,9,4,1,25,0.52,3374\n41,110,120,15,8,4,2,11,0.59,3119\n42,123,130,18,8,4,2,43,0.39,3268\n43,212,230,39,12,5,3,202,4.29,3648\n44,145,145,18,8,4,2,44,0.22,2783\n45,129,135,10,6,3,1,15,1.0,2438\n46,143,145,21,7,4,2,10,1.2,3529\n47,247,252,29,9,4,2,4,1.25,4626\n48,111,120,15,8,3,1,97,1.11,3205\n49,133,145,26,7,3,1,42,0.36,3059\n"
    }
   ],
   "source": [
    "data.to_csv(sys.stdout, na_rep='NULL') # will replace all empty values with 'NULL'\n",
    "# with no other options specified the row and column labels will be written to the file \n",
    "# however you can disable them \n",
    "data.to_csv('exampledata/output.csv', index=False, header=False) #this file has been saved with no index or header "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Delimited Formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   a  b  c\n0  1  2  3\n1  1  2  3",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "bad_data = pd.read_csv('exampledata/bad_csv.csv')\n",
    "bad_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the elements are represented in double quote marks. This is more common than usual. in this case it may be necessary to manually read in the file using pythons built-in csv module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\"a\",\"b\",\"c\"\n\"1\",\"2\",\"3\"\n\"1\",\"2\",\"3\"\n"
    }
   ],
   "source": [
    "!cat exampledata/bad_csv.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['a', 'b', 'c']\n['1', '2', '3']\n['1', '2', '3']\n"
    }
   ],
   "source": [
    "import csv\n",
    "f = open('exampledata/bad_csv.csv')\n",
    "reader = csv.reader(f)\n",
    "\n",
    "for line in reader: \n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from here, it's up to you to do the wrangling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "with open('exampledata/bad_csv.csv') as f: \n",
    "    lines = list(csv.reader(f))\n",
    "\n",
    "header, values = lines[0], lines[1:] #lines 0 is the header. lines 1 and onwards are the values.\n",
    "\n",
    "# Now create a dictionary of data columns \n",
    "# *values collects all the positions in the tuple\n",
    "# zip joins a list all positional elements together in a tuple \n",
    "\n",
    "data_dict = {h: v for h, v in zip(header, zip(*values))} \n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv files can come in many different forms you can specify your own by creating a class like the one below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "hello;this;is;a;string\n1;2;3;4\n%;5;6;7\n"
    }
   ],
   "source": [
    "class my_dialect(csv.Dialect):\n",
    "    lineterminator = '\\n'\n",
    "    delimiter = ';'\n",
    "    quotechar = '\"'\n",
    "    quoting = csv.QUOTE_MINIMAL\n",
    "f = open('exampledata/homes.csv')\n",
    "reader = csv.reader(f, delimiter='|')\n",
    "\n",
    "with open('exampledata/mydata.csv', 'w') as f:\n",
    "    writer = csv.writer(f, dialect=my_dialect)\n",
    "    writer.writerow(('hello', 'this', 'is', 'a', 'string'))\n",
    "    writer.writerow(('1', '2', '3', '4'))\n",
    "    writer.writerow(('%', '5', '6', '7'))\n",
    "\n",
    "!cat 'exampledata/mydata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Data\n",
    "JSON JavaScript Object Notations has become the standard format for sending HTTPS requests. (asking for and receiving data from servers through the web) below is an example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = \"\"\"\n",
    "  {\"name\": [\"Ollie\", \"NaN\"],\n",
    "  \"places_lived\": [\"battle\", \"robertsbridge\"],\n",
    "  \"pet\": [\"Mac\", \"philip\"],\n",
    "  \"siblings\":[\"thomas\", \"Giles\"]\n",
    "  }\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON is very similar to python code apart from some nuances. All keys must be strings. Null is represented by null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'name': ['Ollie', 'NaN'],\n 'places_lived': ['battle', 'robertsbridge'],\n 'pet': ['Mac', 'philip'],\n 'siblings': ['thomas', 'Giles']}"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "import json \n",
    "result = json.loads(obj) # loads a JSON object into python\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'{\"name\": [\"Ollie\", \"NaN\"], \"places_lived\": [\"battle\", \"robertsbridge\"], \"pet\": [\"Mac\", \"philip\"], \"siblings\": [\"thomas\", \"Giles\"]}'"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "asjson = json.dumps(result) #converts to JSON\n",
    "asjson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "once you have received the JSON into data you can load it into a dataframe like any python dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "         name   places_lived\nMac     Ollie         battle\nphilip    NaN  robertsbridge",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>places_lived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Mac</th>\n      <td>Ollie</td>\n      <td>battle</td>\n    </tr>\n    <tr>\n      <th>philip</th>\n      <td>NaN</td>\n      <td>robertsbridge</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "df = pd.DataFrame(result, index=result['pet'])\n",
    "df[['name', 'places_lived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XML and HTML: Web Scraping\n",
    "pandas has a built-in function, read_html which uses a few different methods to read tables out of HTML files as a DataFrame. you must have 'lxml' and 'beautifulsoup4 html5lib' installed. You can use pip to install them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[  First name    Last name  Age\n 0       Tinu     Elejogun   14\n 1  Blaszczyk  Kostrzewski   25\n 2       Lily    McGarrett   18\n 3  Olatunkbo     Chijiaku   22\n 4   Adrienne     Anthoula   22\n 5     Axelia   Athanasios   22\n 6  Jon-Kabat         Zinn   22\n 7    Thabang        Mosoa   15\n 8   Kgaogelo        Mosoa   11,\n    Ã—  1  2  3\n 0  1  1  2  3\n 1  2  2  4  6\n 2  3  3  6  9,\n                          0             1  \\\n 0  Standard Representation           NaN   \n 1                    2 3 1           NaN   \n 2              Health Risk  Flammability   \n 3                  Level 3       Level 2   \n \n                                                    2        3  \n 0                             Tabular Representation      NaN  \n 1  Risk levels of hazardous materials in this fac...      NaN  \n 2                                         Reactivity  Special  \n 3                                            Level 1      NaN  ,\n   Health Risk Flammability Reactivity  Special\n 0     Level 3      Level 2    Level 1      NaN,\n     0                                                  1\n 0 NaN  Look up table in Wiktionary, the free dictionary.,\n   vteVisualization of technical information  \\\n 0                                    Fields   \n 1                               Image types   \n 2                                    People   \n 3                            Related topics   \n \n          vteVisualization of technical information.1  \n 0  Biological data visualization Chemical imaging...  \n 1  Chart Diagram Engineering drawing Graph of a f...  \n 2  Jacques Bertin Cynthia Brewer Stuart Card Shee...  \n 3  Cartography Chartjunk Computer graphics in com...  ]"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "tables = pd.read_html('exampledata/test_webpage.html')\n",
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "above shows all of the tabular data from the html file as a DataFrame object. the read_html method searches the code to find the <table> tags to find tabular data and then loads it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "  First name    Last name  Age\n0       Tinu     Elejogun   14\n1  Blaszczyk  Kostrzewski   25\n2       Lily    McGarrett   18\n3  Olatunkbo     Chijiaku   22\n4   Adrienne     Anthoula   22\n5     Axelia   Athanasios   22\n6  Jon-Kabat         Zinn   22\n7    Thabang        Mosoa   15\n8   Kgaogelo        Mosoa   11",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>First name</th>\n      <th>Last name</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Tinu</td>\n      <td>Elejogun</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Blaszczyk</td>\n      <td>Kostrzewski</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Lily</td>\n      <td>McGarrett</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Olatunkbo</td>\n      <td>Chijiaku</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Adrienne</td>\n      <td>Anthoula</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Axelia</td>\n      <td>Athanasios</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Jon-Kabat</td>\n      <td>Zinn</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Thabang</td>\n      <td>Mosoa</td>\n      <td>15</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Kgaogelo</td>\n      <td>Mosoa</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "table1 = tables[0]\n",
    "table1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with Web APIs \n",
    "a number of Websites provide APIs for data collection via JSON. There are a number of ways to accsess these APIs from python. the following is a simple way.  \n",
    "<br/>\n",
    "to find the last 30 GitHub issues for pandas we can make a get HTTP request using the add-on requests library: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<Response [200]>"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "import requests\n",
    "url = 'https://api.github.com/repos/pandas-dev/pandas/issues'\n",
    "resp = requests.get(url)\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Response object's json method will return a dictionary containing JSON parsed into native python objects:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'url': 'https://api.github.com/repos/pandas-dev/pandas/issues/35388',\n 'repository_url': 'https://api.github.com/repos/pandas-dev/pandas',\n 'labels_url': 'https://api.github.com/repos/pandas-dev/pandas/issues/35388/labels{/name}',\n 'comments_url': 'https://api.github.com/repos/pandas-dev/pandas/issues/35388/comments',\n 'events_url': 'https://api.github.com/repos/pandas-dev/pandas/issues/35388/events',\n 'html_url': 'https://github.com/pandas-dev/pandas/issues/35388',\n 'id': 664156158,\n 'node_id': 'MDU6SXNzdWU2NjQxNTYxNTg=',\n 'number': 35388,\n 'title': \"BUG: timezone-aware DatetimeIndex doesn't handle offsets very well\",\n 'user': {'login': 'rwijtvliet',\n  'id': 4106013,\n  'node_id': 'MDQ6VXNlcjQxMDYwMTM=',\n  'avatar_url': 'https://avatars1.githubusercontent.com/u/4106013?v=4',\n  'gravatar_id': '',\n  'url': 'https://api.github.com/users/rwijtvliet',\n  'html_url': 'https://github.com/rwijtvliet',\n  'followers_url': 'https://api.github.com/users/rwijtvliet/followers',\n  'following_url': 'https://api.github.com/users/rwijtvliet/following{/other_user}',\n  'gists_url': 'https://api.github.com/users/rwijtvliet/gists{/gist_id}',\n  'starred_url': 'https://api.github.com/users/rwijtvliet/starred{/owner}{/repo}',\n  'subscriptions_url': 'https://api.github.com/users/rwijtvliet/subscriptions',\n  'organizations_url': 'https://api.github.com/users/rwijtvliet/orgs',\n  'repos_url': 'https://api.github.com/users/rwijtvliet/repos',\n  'events_url': 'https://api.github.com/users/rwijtvliet/events{/privacy}',\n  'received_events_url': 'https://api.github.com/users/rwijtvliet/received_events',\n  'type': 'User',\n  'site_admin': False},\n 'labels': [{'id': 76811,\n   'node_id': 'MDU6TGFiZWw3NjgxMQ==',\n   'url': 'https://api.github.com/repos/pandas-dev/pandas/labels/Bug',\n   'name': 'Bug',\n   'color': 'e10c02',\n   'default': False,\n   'description': None},\n  {'id': 1954720290,\n   'node_id': 'MDU6TGFiZWwxOTU0NzIwMjkw',\n   'url': 'https://api.github.com/repos/pandas-dev/pandas/labels/Needs%20Triage',\n   'name': 'Needs Triage',\n   'color': '0052cc',\n   'default': False,\n   'description': 'Issue that has not been reviewed by a pandas team member'}],\n 'state': 'open',\n 'locked': False,\n 'assignee': None,\n 'assignees': [],\n 'milestone': None,\n 'comments': 0,\n 'created_at': '2020-07-23T02:07:01Z',\n 'updated_at': '2020-07-23T02:09:34Z',\n 'closed_at': None,\n 'author_association': 'NONE',\n 'active_lock_reason': None,\n 'body': \"- [x] I have checked that this issue has not already been reported.\\r\\n\\r\\n- [x] I have confirmed this bug exists on the latest version of pandas.\\r\\n\\r\\n- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.\\r\\n\\r\\n---\\r\\n\\r\\n#### Code Sample, a copy-pastable example\\r\\n\\r\\n```python\\r\\nimport pandas as pd\\r\\ni = pd.date_range('2020-03-28', periods=4, freq='D', tz='Europe/Berlin')\\r\\ni # DatetimeIndex(['2020-03-28 00:00:00+01:00',  '2020-03-29 00:00:00+01:00', '2020-03-30 00:00:00+02:00', '2020-03-31 00:00:00+02:00'], dtype='datetime64[ns, Europe/Berlin]', freq='D')\\r\\ni[0] + i.freq == i[1] #True\\r\\ni[2] + i.freq == i[3] #True\\r\\ni[1] + i.freq == i[2] #False (!)\\r\\n```\\r\\n\\r\\n#### Problem description\\r\\n\\r\\nVariably-spaced timestamps are not handled well, if the variation is caused by DST. The result of `i[1] + i.freq` is \\r\\n`Timestamp('2020-03-30 01:00:00+0200', tz='Europe/Berlin', freq='D')`, whereas \\r\\n`Timestamp('2020-03-30 00:00:00+0200', tz='Europe/Berlin', freq='D')` was expected.\\r\\n\\r\\nThis is in contrast to timestamps where the variation is caused by e.g. months being different lengths, which *are* handled correctly.\\r\\n\\r\\n#### Output of ``pd.show_versions()``\\r\\n\\r\\n<details>\\r\\n\\r\\nINSTALLED VERSIONS\\r\\n------------------\\r\\ncommit           : None\\r\\npython           : 3.8.3.final.0\\r\\npython-bits      : 64\\r\\nOS               : Windows\\r\\nOS-release       : 10\\r\\nmachine          : AMD64\\r\\nprocessor        : Intel64 Family 6 Model 158 Stepping 10, GenuineIntel\\r\\nbyteorder        : little\\r\\nLC_ALL           : None\\r\\nLANG             : en\\r\\nLOCALE           : de_DE.cp1252\\r\\n\\r\\npandas           : 1.0.5\\r\\nnumpy            : 1.18.5\\r\\npytz             : 2020.1\\r\\ndateutil         : 2.8.1\\r\\npip              : 20.1.1\\r\\nsetuptools       : 49.2.0.post20200714\\r\\nCython           : None\\r\\npytest           : 5.4.3\\r\\nhypothesis       : None\\r\\nsphinx           : None\\r\\nblosc            : None\\r\\nfeather          : None\\r\\nxlsxwriter       : None\\r\\nlxml.etree       : None\\r\\nhtml5lib         : 1.0.1\\r\\npymysql          : None\\r\\npsycopg2         : None\\r\\njinja2           : 2.11.2\\r\\nIPython          : 7.16.1\\r\\npandas_datareader: None\\r\\nbs4              : 4.9.1\\r\\nbottleneck       : None\\r\\nfastparquet      : None\\r\\ngcsfs            : None\\r\\nlxml.etree       : None\\r\\nmatplotlib       : 3.2.2\\r\\nnumexpr          : None\\r\\nodfpy            : None\\r\\nopenpyxl         : 3.0.4\\r\\npandas_gbq       : None\\r\\npyarrow          : None\\r\\npytables         : None\\r\\npytest           : 5.4.3\\r\\npyxlsb           : None\\r\\ns3fs             : None\\r\\nscipy            : 1.5.0\\r\\nsqlalchemy       : 1.3.18\\r\\ntables           : None\\r\\ntabulate         : None\\r\\nxarray           : None\\r\\nxlrd             : 1.2.0\\r\\nxlwt             : None\\r\\nxlsxwriter       : None\\r\\nnumba            : None\\r\\n\\r\\n</details>\\r\\n\",\n 'performed_via_github_app': None}"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "data = resp.json()\n",
    "data[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"BUG: timezone-aware DatetimeIndex doesn't handle offsets very well\""
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "data[1]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   number                                              title  \\\n0   35389  ENH: Request for `Index.to_string` & `MultiInd...   \n1   35388  BUG: timezone-aware DatetimeIndex doesn't hand...   \n2   35387  Display dataframe name or title when using dis...   \n3   35386  CLN: resolve isort mypy import confilict test_...   \n4   35385                                         fix #35227   \n5   35384  ENH: The parameter merge_cells parameter in fu...   \n6   35383  Drop similar rows of dataframe except for one ...   \n7   35382  BUG: Inconsistent ordering of rows when mergin...   \n8   35381                                    Storage options   \n9   35380  CLN: resolve isort mypy import confilict test_...   \n\n                                              labels state  \n0  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n1  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n2  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n3                                                 []  open  \n4                                                 []  open  \n5  [{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...  open  \n6  [{'id': 1954720290, 'node_id': 'MDU6TGFiZWwxOT...  open  \n7  [{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...  open  \n8                                                 []  open  \n9  [{'id': 211029535, 'node_id': 'MDU6TGFiZWwyMTE...  open  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>title</th>\n      <th>labels</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>35389</td>\n      <td>ENH: Request for `Index.to_string` &amp; `MultiInd...</td>\n      <td>[{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>35388</td>\n      <td>BUG: timezone-aware DatetimeIndex doesn't hand...</td>\n      <td>[{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>35387</td>\n      <td>Display dataframe name or title when using dis...</td>\n      <td>[{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35386</td>\n      <td>CLN: resolve isort mypy import confilict test_...</td>\n      <td>[]</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35385</td>\n      <td>fix #35227</td>\n      <td>[]</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>35384</td>\n      <td>ENH: The parameter merge_cells parameter in fu...</td>\n      <td>[{'id': 76812, 'node_id': 'MDU6TGFiZWw3NjgxMg=...</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>35383</td>\n      <td>Drop similar rows of dataframe except for one ...</td>\n      <td>[{'id': 1954720290, 'node_id': 'MDU6TGFiZWwxOT...</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>35382</td>\n      <td>BUG: Inconsistent ordering of rows when mergin...</td>\n      <td>[{'id': 76811, 'node_id': 'MDU6TGFiZWw3NjgxMQ=...</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>35381</td>\n      <td>Storage options</td>\n      <td>[]</td>\n      <td>open</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>35380</td>\n      <td>CLN: resolve isort mypy import confilict test_...</td>\n      <td>[{'id': 211029535, 'node_id': 'MDU6TGFiZWwyMTE...</td>\n      <td>open</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "issues = pd.DataFrame(data, columns=['number', 'title', 'labels', 'state'])\n",
    "issues.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "\n",
    "# Interacting with Databases\n",
    "in the business settings many companies may store their data in SQL based relational databases such as SQL Server, PostgreSQ, and MySQL.  loading data from SQL into a DataFrame is fairly straightfoward, and pandas has some functions to simplify the process. As an Exmaple, lets create a SQLite database using Python's built-in sqlite3 driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<sqlite3.Cursor at 0x2707bf59880>"
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "source": [
    "import sqlite3\n",
    "query = \"\"\"\n",
    "CREATE TABLE test\n",
    "(a VARCHAR(20), b VARCHAR(20), \n",
    " c REAL,        d INTEGER\n",
    "); \"\"\"\n",
    "\n",
    "con = sqlite3.connect('mydata.sqlite')\n",
    "con.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<sqlite3.Cursor at 0x2707d703ab0>"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "# insert a few rows of data \n",
    "data = [('Atlanta', 'Georgia', 1.25, 6),\n",
    "         ('Tallahassee', 'Florida', 2.6, 3),\n",
    "         ('Sacramento', 'California', 1.7, 5)]\n",
    "stmt = \"INSERT INTO test VALUES(?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[('Atlanta', 'Georgia', 1.25, 6),\n ('Tallahassee', 'Florida', 2.6, 3),\n ('Sacramento', 'California', 1.7, 5)]"
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "con.commit()\n",
    "# Most Python SQL drivers return a list of tuples whn selecting data from a talbe \n",
    "cursor = con.execute('select * from test')\n",
    "rows = cursor.fetchall()\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can pass the list of tuples to the DataFrame constructor, but you need the column names, contained in the cursor's description attribute: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(('a', None, None, None, None, None, None),\n ('b', None, None, None, None, None, None),\n ('c', None, None, None, None, None, None),\n ('d', None, None, None, None, None, None))"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "cursor.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             a           b     c  d\n0      Atlanta     Georgia  1.25  6\n1  Tallahassee     Florida  2.60  3\n2   Sacramento  California  1.70  5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a</th>\n      <th>b</th>\n      <th>c</th>\n      <th>d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Atlanta</td>\n      <td>Georgia</td>\n      <td>1.25</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tallahassee</td>\n      <td>Florida</td>\n      <td>2.60</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sacramento</td>\n      <td>California</td>\n      <td>1.70</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 84
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(rows, columns=[x[0] for x in cursor.description])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}